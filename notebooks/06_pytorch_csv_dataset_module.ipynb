{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "from typing import Union, Tuple, List, Optional, TypeVar, Type\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.engineer.geowiki import GeoWikiDataInstance\n",
    "from src.exporters.sentinel.cloudfree import BANDS\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeowikiDatasetType = TypeVar('GeowikiDatasetType', bound='Parent') # for annotations\n",
    "\n",
    "class GeowikiDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir: Union[Path, str],\n",
    "                csv_file: str='geowiki_labels_country_crs4326.csv',\n",
    "                countries_subset: Optional[List[str]]=None,\n",
    "                countries_to_weight: Optional[List[str]]=None,\n",
    "                remove_b1_b10: bool=True,\n",
    "                labels: Optional[pd.DataFrame]=None # if this is passed csv_file will be ignored\n",
    "                ) -> None:\n",
    "        \n",
    "        # Constructor arguments\n",
    "        self.data_dir = data_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.countries_subset = countries_subset\n",
    "        self.countries_to_weight = countries_to_weight\n",
    "        self.remove_b1_b10 = remove_b1_b10\n",
    "        \n",
    "        # Instance parameters\n",
    "        self.bands_to_remove = [\"B1\", \"B10\"]\n",
    "        self.crop_probability_threshold = 0.5\n",
    "        self.normalizing_dict = None\n",
    "\n",
    "        # Functions\n",
    "        if labels is None:\n",
    "            self.labels = pd.read_csv(self.data_dir / self.csv_file)\n",
    "            self.labels.loc[self.labels['country'].isnull(), 'country'] = 'unknown'\n",
    "            if self.countries_subset:\n",
    "                self.labels = self.labels[self.labels['country'].str.lower().isin(list(map(str.lower, self.countries_subset)))].reset_index(drop=True)\n",
    "        else:\n",
    "            self.labels = labels\n",
    "        self.picke_files = self.get_pickle_files_paths(self.data_dir / 'all')\n",
    "        self.file_identifiers_countries_to_weight = self.get_file_ids_for_countries(self.countries_to_weight)\n",
    "        print('length labels:', len(self.labels))\n",
    "        print('length pickle files:', len(self.picke_files))\n",
    "        print('length local ids:', len(self.file_identifiers_countries_to_weight))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Return the data, label, and weight tensors.\n",
    "        \"\"\"\n",
    "        target_file = self.picke_files[index]\n",
    "        identifier = int(target_file.name.split('_')[0])\n",
    "\n",
    "        with target_file.open(\"rb\") as f:\n",
    "            target_datainstance = pickle.load(f)\n",
    "\n",
    "        if isinstance(target_datainstance, GeoWikiDataInstance):\n",
    "            if self.crop_probability_threshold is None:\n",
    "                label = target_datainstance.crop_probability\n",
    "            else:\n",
    "                label = int(target_datainstance.crop_probability >= self.crop_probability_threshold)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unrecognized data instance type {type(target_datainstance)}\")\n",
    "\n",
    "        is_local = 0\n",
    "        if identifier in self.file_identifiers_countries_to_weight:\n",
    "           is_local = 1\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(\n",
    "                self.remove_bands(x=self._normalize(target_datainstance.labelled_array))\n",
    "            ).float(),\n",
    "            torch.tensor(label).float(),\n",
    "            torch.tensor(is_local).long(),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_output_classes(self) -> int:\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def num_input_features(self) -> int:\n",
    "        # assumes the first value in the tuple is x\n",
    "        assert len(self.pickle_files) > 0, \"No files to load!\"\n",
    "        output_tuple = self[0]\n",
    "        return output_tuple[0].shape[1]\n",
    "\n",
    "    @property\n",
    "    def num_timesteps(self) -> int:\n",
    "        # assumes the first value in the tuple is x\n",
    "        assert len(self.pickle_files) > 0, \"No files to load!\"\n",
    "        output_tuple = self[0]\n",
    "        return output_tuple[0].shape[0]\n",
    "\n",
    "    def remove_bands(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Expects the input to be of shape [timesteps, bands]\n",
    "        \"\"\"\n",
    "        if self.remove_b1_b10:\n",
    "            indices_to_remove: List[int] = []\n",
    "            for band in self.bands_to_remove:\n",
    "                indices_to_remove.append(BANDS.index(band))\n",
    "\n",
    "            bands_index = 1 if len(x.shape) == 2 else 2\n",
    "            indices_to_keep = [i for i in range(x.shape[bands_index]) if i not in indices_to_remove]\n",
    "            if len(x.shape) == 2:\n",
    "                # timesteps, bands\n",
    "                return x[:, indices_to_keep]\n",
    "            else:\n",
    "                # batches, timesteps, bands\n",
    "                return x[:, :, indices_to_keep]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _normalize(self, array: np.ndarray) -> np.ndarray:\n",
    "        if self.normalizing_dict is None:\n",
    "            return array\n",
    "        else:\n",
    "            return (array - self.normalizing_dict[\"mean\"]) / self.normalizing_dict[\"std\"]\n",
    "\n",
    "    def get_pickle_files_paths(self, folder_path: Path) -> Tuple[List[Path]]:\n",
    "        file_paths = self.labels.filename.tolist()\n",
    "        print('Checking for data files')\n",
    "        pickle_files = [path for path in tqdm(folder_path.glob('*.pkl')) if path.name in file_paths]\n",
    "        self._check_label_files(pickle_files)\n",
    "        return pickle_files\n",
    "\n",
    "    def _check_label_files(self, pickle_files) -> None:\n",
    "        same_files = set([file.name for file in pickle_files]) == set(self.labels.filename.tolist())\n",
    "        assert same_files, \"Some pickle files of the labels were not found!\"\n",
    "        print('All pickle files were found!')\n",
    "\n",
    "    def get_file_ids_for_countries(self, countries_list: List[str]) -> List[int]:\n",
    "        file_ids = []\n",
    "        if countries_list:\n",
    "            countries_list_lowercase = list(map(str.lower, countries_list))\n",
    "            file_ids.extend(self.labels[self.labels['country'].str.lower().isin(countries_list_lowercase)]['identifier'].tolist())\n",
    "        return file_ids\n",
    "\n",
    "    @classmethod\n",
    "    def train_val_split(cls: Type[GeowikiDatasetType], class_instance: Type[GeowikiDatasetType], train_size: float=0.8, stratify_column: Optional[str]=None) -> Tuple[GeowikiDatasetType]:\n",
    "        # Split labels dataframe\n",
    "        stratify = None if not stratify_column else class_instance.labels[stratify_column]\n",
    "        df_train, df_val = train_test_split(class_instance.labels, train_size=train_size, stratify=stratify, random_state=42)\n",
    "        df_train.reset_index(drop=True, inplace=True) \n",
    "        df_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Create two new GeowikiDataset instances (train and val)\n",
    "        print('Train split')\n",
    "        train_dataset = cls(class_instance.data_dir, countries_to_weight=class_instance.countries_to_weight, labels=df_train)\n",
    "        print('Val split')\n",
    "        val_dataset = cls(class_instance.data_dir, countries_to_weight=class_instance.countries_to_weight, labels=df_val)\n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    def get_file_by_identifier(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for data files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35599it [00:00, 36993.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pickle files were found!\n",
      "length labels: 2284\n",
      "length pickle files: 2284\n",
      "length local ids: 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('../data/features/geowiki_landcover_2017')\n",
    "subset = ['Ghana', 'Togo', 'Nigeria', 'Chad', 'Democratic Republic of the Congo', 'Ethiopia', 'Chad', 'Mali']\n",
    "dataset = GeowikiDataset(data_dir, 'geowiki_labels_country_crs4326.csv', countries_subset=subset, countries_to_weight=['Nigeria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12178</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>9.651814</td>\n",
       "      <td>0.550622</td>\n",
       "      <td>0.154286</td>\n",
       "      <td>12178_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10292</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>3.952363</td>\n",
       "      <td>24.249976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10292_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6515</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-10.047612</td>\n",
       "      <td>24.749978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6515_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13225</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.651823</td>\n",
       "      <td>37.550612</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>13225_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11281</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>7.452379</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11281_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>10224</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>3.452360</td>\n",
       "      <td>21.749965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10224_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>13134</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.452397</td>\n",
       "      <td>-5.249979</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>13134_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>14245</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>13.651742</td>\n",
       "      <td>20.952351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14245_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Chad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>14813</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>14.952413</td>\n",
       "      <td>-4.249975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14813_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>12805</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>10.952395</td>\n",
       "      <td>4.749977</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>12805_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                   date        lat        lon     label  \\\n",
       "0          12178  2017-03-28_2018-03-28   9.651814   0.550622  0.154286   \n",
       "1          10292  2017-03-28_2018-03-28   3.952363  24.249976  0.000000   \n",
       "2           6515  2017-03-28_2018-03-28 -10.047612  24.749978  0.000000   \n",
       "3          13225  2017-03-28_2018-03-28  11.651823  37.550612  0.160000   \n",
       "4          11281  2017-03-28_2018-03-28   7.452379   5.249979  0.000000   \n",
       "...          ...                    ...        ...        ...       ...   \n",
       "2279       10224  2017-03-28_2018-03-28   3.452360  21.749965  0.000000   \n",
       "2280       13134  2017-03-28_2018-03-28  11.452397  -5.249979  0.553846   \n",
       "2281       14245  2017-03-28_2018-03-28  13.651742  20.952351  0.000000   \n",
       "2282       14813  2017-03-28_2018-03-28  14.952413  -4.249975  0.000000   \n",
       "2283       12805  2017-03-28_2018-03-28  10.952395   4.749977  0.940000   \n",
       "\n",
       "                             filename                           country  \n",
       "0     12178_2017-03-28_2018-03-28.pkl                              Togo  \n",
       "1     10292_2017-03-28_2018-03-28.pkl  Democratic Republic of the Congo  \n",
       "2      6515_2017-03-28_2018-03-28.pkl  Democratic Republic of the Congo  \n",
       "3     13225_2017-03-28_2018-03-28.pkl                          Ethiopia  \n",
       "4     11281_2017-03-28_2018-03-28.pkl                           Nigeria  \n",
       "...                               ...                               ...  \n",
       "2279  10224_2017-03-28_2018-03-28.pkl  Democratic Republic of the Congo  \n",
       "2280  13134_2017-03-28_2018-03-28.pkl                              Mali  \n",
       "2281  14245_2017-03-28_2018-03-28.pkl                              Chad  \n",
       "2282  14813_2017-03-28_2018-03-28.pkl                              Mali  \n",
       "2283  12805_2017-03-28_2018-03-28.pkl                           Nigeria  \n",
       "\n",
       "[2284 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split\n",
      "Checking for data files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35599it [00:00, 45286.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pickle files were found!\n",
      "length labels: 1827\n",
      "length pickle files: 1827\n",
      "length local ids: 374\n",
      "Val split\n",
      "Checking for data files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35599it [00:00, 144565.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pickle files were found!\n",
      "length labels: 457\n",
      "length pickle files: 457\n",
      "length local ids: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = dataset.train_val_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13582</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>12.452402</td>\n",
       "      <td>4.749977</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>13582_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13309</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.952399</td>\n",
       "      <td>6.249984</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>13309_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11739</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>8.651809</td>\n",
       "      <td>9.952390</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>11739_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7507</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-6.749986</td>\n",
       "      <td>17.952337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7507_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10968</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>6.452374</td>\n",
       "      <td>35.250026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10968_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>15040</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>15.651751</td>\n",
       "      <td>-4.047584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15040_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>14366</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>13.952408</td>\n",
       "      <td>-6.249984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14366_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>6800</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-9.047607</td>\n",
       "      <td>26.749988</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>6800_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>11427</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>7.952381</td>\n",
       "      <td>47.749994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11427_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>14980</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>15.452415</td>\n",
       "      <td>-6.749986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14980_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                   date        lat        lon     label  \\\n",
       "0          13582  2017-03-28_2018-03-28  12.452402   4.749977  0.500000   \n",
       "1          13309  2017-03-28_2018-03-28  11.952399   6.249984  0.150000   \n",
       "2          11739  2017-03-28_2018-03-28   8.651809   9.952390  0.180000   \n",
       "3           7507  2017-03-28_2018-03-28  -6.749986  17.952337  0.000000   \n",
       "4          10968  2017-03-28_2018-03-28   6.452374  35.250026  0.000000   \n",
       "...          ...                    ...        ...        ...       ...   \n",
       "1822       15040  2017-03-28_2018-03-28  15.651751  -4.047584  0.000000   \n",
       "1823       14366  2017-03-28_2018-03-28  13.952408  -6.249984  0.000000   \n",
       "1824        6800  2017-03-28_2018-03-28  -9.047607  26.749988  0.006667   \n",
       "1825       11427  2017-03-28_2018-03-28   7.952381  47.749994  0.000000   \n",
       "1826       14980  2017-03-28_2018-03-28  15.452415  -6.749986  0.000000   \n",
       "\n",
       "                             filename                           country  \n",
       "0     13582_2017-03-28_2018-03-28.pkl                           Nigeria  \n",
       "1     13309_2017-03-28_2018-03-28.pkl                           Nigeria  \n",
       "2     11739_2017-03-28_2018-03-28.pkl                           Nigeria  \n",
       "3      7507_2017-03-28_2018-03-28.pkl  Democratic Republic of the Congo  \n",
       "4     10968_2017-03-28_2018-03-28.pkl                          Ethiopia  \n",
       "...                               ...                               ...  \n",
       "1822  15040_2017-03-28_2018-03-28.pkl                              Mali  \n",
       "1823  14366_2017-03-28_2018-03-28.pkl                              Mali  \n",
       "1824   6800_2017-03-28_2018-03-28.pkl  Democratic Republic of the Congo  \n",
       "1825  11427_2017-03-28_2018-03-28.pkl                          Ethiopia  \n",
       "1826  14980_2017-03-28_2018-03-28.pkl                              Mali  \n",
       "\n",
       "[1827 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13587</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>12.452402</td>\n",
       "      <td>7.249988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13587_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13268</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.851159</td>\n",
       "      <td>21.050626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13268_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Chad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12575</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>10.452392</td>\n",
       "      <td>8.249993</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>12575_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12953</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.250007</td>\n",
       "      <td>-8.047602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12953_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12013</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>9.249997</td>\n",
       "      <td>34.651749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12013_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12253</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>9.851150</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>12253_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>12767</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>10.851155</td>\n",
       "      <td>13.050590</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>12767_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>14275</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>13.651742</td>\n",
       "      <td>-6.047593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14275_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>11413</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>7.952381</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>11413_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>13143</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.452397</td>\n",
       "      <td>11.250007</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>13143_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier                   date        lat        lon     label  \\\n",
       "0         13587  2017-03-28_2018-03-28  12.452402   7.249988  0.000000   \n",
       "1         13268  2017-03-28_2018-03-28  11.851159  21.050626  0.000000   \n",
       "2         12575  2017-03-28_2018-03-28  10.452392   8.249993  0.406667   \n",
       "3         12953  2017-03-28_2018-03-28  11.250007  -8.047602  0.000000   \n",
       "4         12013  2017-03-28_2018-03-28   9.249997  34.651749  0.000000   \n",
       "..          ...                    ...        ...        ...       ...   \n",
       "452       12253  2017-03-28_2018-03-28   9.851150  -0.949385  0.850000   \n",
       "453       12767  2017-03-28_2018-03-28  10.851155  13.050590  0.180000   \n",
       "454       14275  2017-03-28_2018-03-28  13.651742  -6.047593  0.000000   \n",
       "455       11413  2017-03-28_2018-03-28   7.952381   5.249979  0.025000   \n",
       "456       13143  2017-03-28_2018-03-28  11.452397  11.250007  0.026667   \n",
       "\n",
       "                            filename   country  \n",
       "0    13587_2017-03-28_2018-03-28.pkl   Nigeria  \n",
       "1    13268_2017-03-28_2018-03-28.pkl      Chad  \n",
       "2    12575_2017-03-28_2018-03-28.pkl   Nigeria  \n",
       "3    12953_2017-03-28_2018-03-28.pkl      Mali  \n",
       "4    12013_2017-03-28_2018-03-28.pkl  Ethiopia  \n",
       "..                               ...       ...  \n",
       "452  12253_2017-03-28_2018-03-28.pkl     Ghana  \n",
       "453  12767_2017-03-28_2018-03-28.pkl   Nigeria  \n",
       "454  14275_2017-03-28_2018-03-28.pkl      Mali  \n",
       "455  11413_2017-03-28_2018-03-28.pkl   Nigeria  \n",
       "456  13143_2017-03-28_2018-03-28.pkl   Nigeria  \n",
       "\n",
       "[457 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = dataset.labels.filename.tolist()\n",
    "folder_path = dataset.data_dir / 'all'\n",
    "pickle_files = [path for path in tqdm(folder_path.glob('*.pkl')) if path.name in file_paths]\n",
    "pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset[0]\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt by splitting Geowiki dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = math.floor(len(dataset) * test_ratio)\n",
    "lenghts = [len(dataset) - test_size, test_size]\n",
    "lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, lenghts)  #generator is not yet available in this pytorch version, generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.pickle_files # Subset class doesn't inheret properties like pickles files plus I would need to subset those as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With sklearn train test split on dataframe with labels and then create separate Geowiki datasets for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[df['country'].isin(['Nigeria', 'Ghana'])]\n",
    "df_subset.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_subset, test_size=0.1, stratify=df_subset['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_subset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['country'] == 'Ghana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].value_counts().to_csv('geowiki_points_per_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOS:\n",
    "- Figure out normalizing dict\n",
    "- Support splitting dataset into train/val and update attributes (self.labels, self.pickle_files)\n",
    "    - Could either create dataset and split dataset, or split dataframe with sklearn and then create separate Geowiki datasets for each subset --> went for a hybrid\n",
    "    - Stratify:\n",
    "        - By country -> OK (just need to get rid of nans if there are any)\n",
    "        - By label (would need to define therhesold first)\n",
    "        - By both (https://stackoverflow.com/questions/45516424/sklearn-train-test-split-on-pandas-stratify-by-multiple-columns)\n",
    "- Test multihead training with Togo and then Nigeria or two countries\n",
    "- Train of subset of countries\n",
    "- Later maybe see a way if I could just inherent from LandTypeClassificationDataset so I don't repeat too much code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('togo-paper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d702b24b358fb38573032b2736288a41648cae2db041d7fdb41486d06c5511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
