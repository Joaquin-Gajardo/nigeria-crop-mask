{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pickle\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.engineer.geowiki import GeoWikiDataInstance\n",
    "from src.exporters.sentinel.cloudfree import BANDS\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeowikiDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir: Union[Path, str],\n",
    "                csv_file: str='geowiki_labels_country_crs4326.csv',\n",
    "                remove_b1_b10: bool=True) -> None:\n",
    "        # Constructor arguments\n",
    "        self.root_dir = root_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.remove_b1_b10 = remove_b1_b10\n",
    "        # Instance parameters\n",
    "        self.bands_to_remove = [\"B1\", \"B10\"]\n",
    "        self.crop_probability_threshold = 0.5\n",
    "        self.local_countries = ['Nigeria', 'Togo', 'Ghana'] # could try with all points in africa\n",
    "        self.normalizing_dict = None\n",
    "        # Functions\n",
    "        self.labels = pd.read_csv(self.root_dir / self.csv_file)\n",
    "        self.picke_files = self.get_pickle_files_paths(self.root_dir / 'all')\n",
    "        self.local_file_identifiers = self.get_local_file_ids()\n",
    "        self.check_labels()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Return the data, label, and weight tensors.\n",
    "        \"\"\"\n",
    "        target_file = self.picke_files[index]\n",
    "        identifier = int(target_file.name.split('_')[0])\n",
    "\n",
    "        with target_file.open(\"rb\") as f:\n",
    "            target_datainstance = pickle.load(f)\n",
    "\n",
    "        if isinstance(target_datainstance, GeoWikiDataInstance):\n",
    "            if self.crop_probability_threshold is None:\n",
    "                label = target_datainstance.crop_probability\n",
    "            else:\n",
    "                label = int(target_datainstance.crop_probability >= self.crop_probability_threshold)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unrecognized data instance type {type(target_datainstance)}\")\n",
    "\n",
    "        is_local = 0\n",
    "        if identifier in self.local_file_identifiers:\n",
    "           is_local = 1\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(\n",
    "                self.remove_bands(x=self._normalize(target_datainstance.labelled_array))\n",
    "            ).float(),\n",
    "            torch.tensor(label).float(),\n",
    "            torch.tensor(is_local).long(),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_output_classes(self) -> int:\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def num_input_features(self) -> int:\n",
    "        # assumes the first value in the tuple is x\n",
    "        assert len(self.pickle_files) > 0, \"No files to load!\"\n",
    "        output_tuple = self[0]\n",
    "        return output_tuple[0].shape[1]\n",
    "\n",
    "    @property\n",
    "    def num_timesteps(self) -> int:\n",
    "        # assumes the first value in the tuple is x\n",
    "        assert len(self.pickle_files) > 0, \"No files to load!\"\n",
    "        output_tuple = self[0]\n",
    "        return output_tuple[0].shape[0]\n",
    "\n",
    "    def remove_bands(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Expects the input to be of shape [timesteps, bands]\n",
    "        \"\"\"\n",
    "        if self.remove_b1_b10:\n",
    "            indices_to_remove: List[int] = []\n",
    "            for band in self.bands_to_remove:\n",
    "                indices_to_remove.append(BANDS.index(band))\n",
    "\n",
    "            bands_index = 1 if len(x.shape) == 2 else 2\n",
    "            indices_to_keep = [i for i in range(x.shape[bands_index]) if i not in indices_to_remove]\n",
    "            if len(x.shape) == 2:\n",
    "                # timesteps, bands\n",
    "                return x[:, indices_to_keep]\n",
    "            else:\n",
    "                # batches, timesteps, bands\n",
    "                return x[:, :, indices_to_keep]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _normalize(self, array: np.ndarray) -> np.ndarray:\n",
    "        if self.normalizing_dict is None:\n",
    "            return array\n",
    "        else:\n",
    "            return (array - self.normalizing_dict[\"mean\"]) / self.normalizing_dict[\"std\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_pickle_files_paths(folder_path: Path) -> Tuple[List[Path]]: \n",
    "        return list(folder_path.glob('*.pkl'))\n",
    "\n",
    "    def check_labels(self) -> None:\n",
    "        is_subset = set([file.name for file in self.picke_files]).issubset(set(self.labels.filename.tolist()))\n",
    "        assert is_subset, \"Some of the pickle files are not present in the provided csv file!\"\n",
    "\n",
    "    def get_local_file_ids(self) -> List[int]:\n",
    "        countries_list_lowercase = list(map(str.lower, self.local_countries))\n",
    "        file_ids = self.labels[self.labels['country'].str.lower().isin(countries_list_lowercase)]['identifier'].tolist()\n",
    "        return file_ids\n",
    "\n",
    "    def subset_by_country(self):\n",
    "        pass\n",
    "\n",
    "    def random_by_country(self):\n",
    "        pass\n",
    "\n",
    "    def get_file_by_identifier(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('../data/features/geowiki_landcover_2017')\n",
    "dataset = GeowikiDataset(root_dir, 'geowiki_labels_country_crs4326.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3233</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-21.547574</td>\n",
       "      <td>138.249959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3233_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2246</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-26.547597</td>\n",
       "      <td>148.250004</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2246_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12913</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>11.151821</td>\n",
       "      <td>-2.848243</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>12913_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Burkina Faso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18861</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>27.452380</td>\n",
       "      <td>56.250033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18861_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32400</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>51.250010</td>\n",
       "      <td>4.952367</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>32400_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                   date        lat         lon     label  \\\n",
       "0        3233  2017-03-28_2018-03-28 -21.547574  138.249959  0.000000   \n",
       "1        2246  2017-03-28_2018-03-28 -26.547597  148.250004  0.800000   \n",
       "2       12913  2017-03-28_2018-03-28  11.151821   -2.848243  0.224000   \n",
       "3       18861  2017-03-28_2018-03-28  27.452380   56.250033  0.000000   \n",
       "4       32400  2017-03-28_2018-03-28  51.250010    4.952367  0.233333   \n",
       "\n",
       "                          filename       country  \n",
       "0   3233_2017-03-28_2018-03-28.pkl     Australia  \n",
       "1   2246_2017-03-28_2018-03-28.pkl     Australia  \n",
       "2  12913_2017-03-28_2018-03-28.pkl  Burkina Faso  \n",
       "3  18861_2017-03-28_2018-03-28.pkl          Iran  \n",
       "4  32400_2017-03-28_2018-03-28.pkl       Belgium  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1606, 0.1863, 0.2670, 0.2753, 0.2995, 0.3166, 0.3207, 0.3426, 0.1343,\n",
       "          0.4140, 0.3225, 0.0914],\n",
       "         [0.1489, 0.1714, 0.2357, 0.2594, 0.2811, 0.3039, 0.2938, 0.3280, 0.0971,\n",
       "          0.3987, 0.2954, 0.1097],\n",
       "         [0.1549, 0.1761, 0.2477, 0.2610, 0.2802, 0.3071, 0.2913, 0.3314, 0.0970,\n",
       "          0.3896, 0.2865, 0.0809],\n",
       "         [0.1511, 0.1722, 0.2384, 0.2545, 0.2757, 0.2952, 0.2954, 0.3192, 0.1522,\n",
       "          0.3897, 0.3005, 0.1068],\n",
       "         [0.1503, 0.1720, 0.2370, 0.2534, 0.2739, 0.2906, 0.2946, 0.3187, 0.1542,\n",
       "          0.3909, 0.3098, 0.1084],\n",
       "         [0.1582, 0.1801, 0.2507, 0.2776, 0.3008, 0.3195, 0.3083, 0.3452, 0.1512,\n",
       "          0.4320, 0.3369, 0.1030],\n",
       "         [0.1600, 0.1866, 0.2597, 0.2689, 0.2896, 0.3178, 0.3016, 0.3434, 0.0741,\n",
       "          0.4374, 0.3362, 0.0746],\n",
       "         [0.1638, 0.1924, 0.2705, 0.2694, 0.2929, 0.3183, 0.3062, 0.3468, 0.0722,\n",
       "          0.4389, 0.3288, 0.0619],\n",
       "         [0.1588, 0.1863, 0.2674, 0.2755, 0.2910, 0.3169, 0.3073, 0.3387, 0.0931,\n",
       "          0.4334, 0.3421, 0.0694],\n",
       "         [0.1628, 0.1921, 0.2690, 0.2705, 0.2888, 0.3244, 0.3005, 0.3528, 0.0537,\n",
       "          0.4436, 0.3302, 0.0553],\n",
       "         [0.1708, 0.2053, 0.2861, 0.2808, 0.3010, 0.3314, 0.3109, 0.3483, 0.0684,\n",
       "          0.4427, 0.3422, 0.0415],\n",
       "         [0.2055, 0.2287, 0.2939, 0.2815, 0.3029, 0.3450, 0.3198, 0.3738, 0.0706,\n",
       "          0.4206, 0.3041, 0.0422]]),\n",
       " tensor(0.),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = dataset[0]\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt by splitting Geowiki dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28480, 7119]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = math.floor(len(dataset) * test_ratio)\n",
    "lenghts = [len(dataset) - test_size, test_size]\n",
    "lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, lenghts)  #generator is not yet available in this pytorch version, generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'pickle_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1e72e20a367f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_files\u001b[0m \u001b[0;31m# Subset class doesn't inheret properties like pickles files plus I would need to subset those as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'pickle_files'"
     ]
    }
   ],
   "source": [
    "train_dataset.pickle_files # Subset class doesn't inheret properties like pickles files plus I would need to subset those as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With sklearn train test split on dataframe with labels and then create separate Geowiki datasets for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Ghana      143\n",
       "Nigeria    490\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df[df['country'].isin(['Nigeria', 'Ghana'])]\n",
    "df_subset.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_subset, test_size=0.1, stratify=df_subset['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Ghana      129\n",
       "Nigeria    440\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Ghana      14\n",
       "Nigeria    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_subset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Ghana      128\n",
       "Nigeria    441\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Ghana      15\n",
       "Nigeria    49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('country').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24442</th>\n",
       "      <td>11061</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>6.952376</td>\n",
       "      <td>-0.249956</td>\n",
       "      <td>0.040</td>\n",
       "      <td>11061_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>11545</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>8.249993</td>\n",
       "      <td>-1.047660</td>\n",
       "      <td>0.032</td>\n",
       "      <td>11545_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17445</th>\n",
       "      <td>11102</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>6.952376</td>\n",
       "      <td>-2.249965</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11102_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32374</th>\n",
       "      <td>10810</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>5.952372</td>\n",
       "      <td>-0.749959</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10810_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17932</th>\n",
       "      <td>11036</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>6.851226</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11036_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27521</th>\n",
       "      <td>12681</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>10.651818</td>\n",
       "      <td>-2.047575</td>\n",
       "      <td>0.290</td>\n",
       "      <td>12681_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16805</th>\n",
       "      <td>10597</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>-1.348236</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10597_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27186</th>\n",
       "      <td>11362</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>7.749991</td>\n",
       "      <td>0.351196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11362_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>10949</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>6.452374</td>\n",
       "      <td>-0.249956</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10949_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>10677</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>5.452370</td>\n",
       "      <td>-2.749968</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10677_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       identifier                   date        lat       lon  label  \\\n",
       "24442       11061  2017-03-28_2018-03-28   6.952376 -0.249956  0.040   \n",
       "1719        11545  2017-03-28_2018-03-28   8.249993 -1.047660  0.032   \n",
       "17445       11102  2017-03-28_2018-03-28   6.952376 -2.249965  0.000   \n",
       "32374       10810  2017-03-28_2018-03-28   5.952372 -0.749959  0.000   \n",
       "17932       11036  2017-03-28_2018-03-28   6.851226 -0.949385  0.000   \n",
       "...           ...                    ...        ...       ...    ...   \n",
       "27521       12681  2017-03-28_2018-03-28  10.651818 -2.047575  0.290   \n",
       "16805       10597  2017-03-28_2018-03-28   5.249979 -1.348236  0.050   \n",
       "27186       11362  2017-03-28_2018-03-28   7.749991  0.351196  0.000   \n",
       "10387       10949  2017-03-28_2018-03-28   6.452374 -0.249956  0.000   \n",
       "9363        10677  2017-03-28_2018-03-28   5.452370 -2.749968  0.000   \n",
       "\n",
       "                              filename country  \n",
       "24442  11061_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "1719   11545_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "17445  11102_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "32374  10810_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "17932  11036_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "...                                ...     ...  \n",
       "27521  12681_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "16805  10597_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "27186  11362_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "10387  10949_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "9363   10677_2017-03-28_2018-03-28.pkl   Ghana  \n",
       "\n",
       "[128 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['country'] == 'Ghana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35486"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts().sum()#.to_csv('geowiki_points_per_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    35486\n",
       "True       113\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2631</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-24.047586</td>\n",
       "      <td>151.750020</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2631_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>35284</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>57.952340</td>\n",
       "      <td>-153.250027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35284_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>14337</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>13.952408</td>\n",
       "      <td>-91.250013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14337_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>21850</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>33.952410</td>\n",
       "      <td>132.250021</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>21850_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>10018</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>2.452356</td>\n",
       "      <td>96.250036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10018_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32111</th>\n",
       "      <td>5606</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-13.750018</td>\n",
       "      <td>126.952386</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>5606_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32730</th>\n",
       "      <td>8796</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-2.749968</td>\n",
       "      <td>-42.047578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8796_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33334</th>\n",
       "      <td>35440</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>58.952345</td>\n",
       "      <td>-2.749968</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>35440_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33455</th>\n",
       "      <td>9149</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-1.547662</td>\n",
       "      <td>-52.250014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9149_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34283</th>\n",
       "      <td>9277</td>\n",
       "      <td>2017-03-28_2018-03-28</td>\n",
       "      <td>-1.047660</td>\n",
       "      <td>109.750008</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>9277_2017-03-28_2018-03-28.pkl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       identifier                   date        lat         lon     label  \\\n",
       "347          2631  2017-03-28_2018-03-28 -24.047586  151.750020  0.100000   \n",
       "462         35284  2017-03-28_2018-03-28  57.952340 -153.250027  0.000000   \n",
       "501         14337  2017-03-28_2018-03-28  13.952408  -91.250013  1.000000   \n",
       "653         21850  2017-03-28_2018-03-28  33.952410  132.250021  0.050000   \n",
       "677         10018  2017-03-28_2018-03-28   2.452356   96.250036  0.000000   \n",
       "...           ...                    ...        ...         ...       ...   \n",
       "32111        5606  2017-03-28_2018-03-28 -13.750018  126.952386  0.046667   \n",
       "32730        8796  2017-03-28_2018-03-28  -2.749968  -42.047578  0.000000   \n",
       "33334       35440  2017-03-28_2018-03-28  58.952345   -2.749968  0.680000   \n",
       "33455        9149  2017-03-28_2018-03-28  -1.547662  -52.250014  0.000000   \n",
       "34283        9277  2017-03-28_2018-03-28  -1.047660  109.750008  0.106667   \n",
       "\n",
       "                              filename country  \n",
       "347     2631_2017-03-28_2018-03-28.pkl     NaN  \n",
       "462    35284_2017-03-28_2018-03-28.pkl     NaN  \n",
       "501    14337_2017-03-28_2018-03-28.pkl     NaN  \n",
       "653    21850_2017-03-28_2018-03-28.pkl     NaN  \n",
       "677    10018_2017-03-28_2018-03-28.pkl     NaN  \n",
       "...                                ...     ...  \n",
       "32111   5606_2017-03-28_2018-03-28.pkl     NaN  \n",
       "32730   8796_2017-03-28_2018-03-28.pkl     NaN  \n",
       "33334  35440_2017-03-28_2018-03-28.pkl     NaN  \n",
       "33455   9149_2017-03-28_2018-03-28.pkl     NaN  \n",
       "34283   9277_2017-03-28_2018-03-28.pkl     NaN  \n",
       "\n",
       "[113 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['country'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOS:\n",
    "- Figure out normalizing dict\n",
    "- Support splitting dataset into train/val and update attributes (self.labels, self.pickle_files)\n",
    "    - Could either create dataset and split dataset, or split dataframe with sklearn and then create separate Geowiki datasets for each subset\n",
    "    - Stratify:\n",
    "        - By country -> OK (just need to get rid of nans if there are any)\n",
    "        - By label (need to define therhesold first)\n",
    "        - By both (https://stackoverflow.com/questions/45516424/sklearn-train-test-split-on-pandas-stratify-by-multiple-columns)\n",
    "- Test multihead training with Togo and then Nigeria or two countries\n",
    "- Train of subset of countries\n",
    "- Later maybe see a way if I could just inherent from LandTypeClassificationDataset so I don't repeat too much code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('togo-paper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d702b24b358fb38573032b2736288a41648cae2db041d7fdb41486d06c5511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
