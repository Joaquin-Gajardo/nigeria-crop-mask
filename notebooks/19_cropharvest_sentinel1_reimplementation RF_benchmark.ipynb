{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "import h5py\n",
    "from itertools import permutations\n",
    "from pathlib import Path\n",
    "from typing import cast, Optional, List, Tuple, Dict, Type, TypeVar, Sequence\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from shapely.geometry import Point\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from cropharvest.datasets import CropHarvest, CropHarvestLabels, Task\n",
    "from cropharvest.columns import NullableColumns, RequiredColumns\n",
    "from cropharvest.config import FEATURES_DIR\n",
    "from cropharvest.engineer import Engineer\n",
    "from cropharvest.utils import load_normalizing_dict\n",
    "from cropharvest.bands import BANDS, DYNAMIC_BANDS, STATIC_BANDS, REMOVED_BANDS\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.models import STR2MODEL, STR2BASE, train_model\n",
    "from src.models.data import LandTypeClassificationDataset, NigeriaCropHarvestDataset, GeowikiCropHarvestDataset\n",
    "\n",
    "S2_BANDS = ['B2','B3','B4','B5','B6','B7','B8','B8A','B9','B11','B12','NDVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_metrics(y_true, y_probs):\n",
    "    roc_auc = roc_auc_score(y_true, y_probs)\n",
    "    y_pred = (y_probs > 0.5).astype(int)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print('RF roc-auc test set:', round(roc_auc, 3))\n",
    "    print('RF precision test set:', round(precision, 3))\n",
    "    print('RF recall test set:', round(recall, 3))\n",
    "    print('RF f1-score test set:', round(f1, 3))\n",
    "    print('RF accuracy test set:', round(acc, 3))\n",
    "\n",
    "    return {'roc_auc': roc_auc, 'precision': precision, 'recall': recall, 'f1': f1, 'acc': acc}\n",
    "\n",
    "def get_model(add_geowiki: bool, add_nigeria: bool, geowiki_subset: str):\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--patience\", type=int, default=10)\n",
    "    parser.add_argument(\"--gpus\", type=int, default=0)\n",
    "    parser.add_argument(\"--wandb\", default=False, action=\"store_true\")\n",
    "\n",
    "    model_args = STR2MODEL[\"land_cover\"].add_model_specific_args(parser).parse_args(args=[])\n",
    "    new_model_args_dict = vars(model_args)\n",
    "\n",
    "    # SET MODIFICATIONS TO DEFAULT MODEL ARGUMENTS:\n",
    "    new_model_args_dict['add_geowiki'] = add_geowiki\n",
    "    new_model_args_dict['add_nigeria'] = add_nigeria\n",
    "    new_model_args_dict['geowiki_subset'] =  geowiki_subset # 'nigeria', 'neighbours1'\n",
    "\n",
    "    new_model_args = Namespace(**new_model_args_dict)\n",
    "    model = STR2MODEL[\"land_cover\"](new_model_args)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_dataset_splits(add_geowiki: bool, add_nigeria: bool, geowiki_subset: str='world', S2_features_only: bool=False):\n",
    "\n",
    "    # Dirty hack, we use landcovermapper class (only supporting lstm model) class to access model splits\n",
    "    lancovermapper = get_model(add_geowiki, add_nigeria, geowiki_subset)\n",
    "\n",
    "    train_dataset = lancovermapper.get_dataset(subset=\"training\").as_array(flatten_x=True, S2_features_only=S2_features_only)\n",
    "    val_dataset = lancovermapper.get_dataset(subset=\"validation\", normalizing_dict=lancovermapper.normalizing_dict).as_array(flatten_x=True, S2_features_only=S2_features_only)\n",
    "    #test_dataset = lancovermapper.get_dataset(subset=\"validation\", normalizing_dict=lancovermapper.normalizing_dict, evaluating=True).as_array(flatten_x=True, S2_features_only=S2_features_only) \n",
    "    test_dataset = lancovermapper.get_dataset(subset=\"testing\", normalizing_dict=lancovermapper.normalizing_dict).as_array(flatten_x=True, S2_features_only=S2_features_only)\n",
    "\n",
    "    return (\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        test_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_subset = ['Nigeria']\n",
    "# geowiki_dataset = GeowikiCropHarvestDataset(root=DATA_DIR/\"cropharvest\", countries_subset=countries_subset)\n",
    "# geowiki_train, geowiki_val = geowiki_dataset.train_val_split(geowiki_dataset)\n",
    "\n",
    "def get_dataset(subset: str, normalizing_dict: Optional[Dict] = None, evaluating: bool = False, add_geowiki: bool=True, add_nigeria: bool=True) -> LandTypeClassificationDataset:       \n",
    "    # Geowiki\n",
    "    geowiki_dataset = None\n",
    "    if add_geowiki:\n",
    "        # Define split\n",
    "        if subset == 'training':\n",
    "            geowiki_dataset = geowiki_train\n",
    "        elif subset == 'validation':\n",
    "            geowiki_dataset = geowiki_val\n",
    "\n",
    "    # Nigeria\n",
    "    nigeria_root_path = DATA_DIR / 'features' / 'nigeria-cropharvest'\n",
    "    nigeria_dataset = None\n",
    "    if add_nigeria or (subset == 'testing') or (subset == \"validation\" and evaluating):\n",
    "        # We want to define Nigeria dataset in the following not mutually exclusive cases: 1) for training (i.e. when add_nigeria=True);\n",
    "        # 2) for testing with test split; 3) for testing with validation split during development (i.e. evaluating=True).\n",
    "        nigeria_dataset = NigeriaCropHarvestDataset(nigeria_root_path, split=subset)      \n",
    "\n",
    "    return LandTypeClassificationDataset(\n",
    "        subset=subset,\n",
    "        include_geowiki=add_geowiki,\n",
    "        include_nigeria=add_nigeria,\n",
    "        evaluating=evaluating,\n",
    "        geowiki_dataset=geowiki_dataset,\n",
    "        nigeria_dataset=nigeria_dataset,\n",
    "        normalizing_dict=normalizing_dict,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate on Nigeria test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training only on geowiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Geowiki world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Total number of files used for training: 19808\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Total number of files used for training: 19808\n",
      "Number of instances in Geowiki validation set: 4953\n",
      "Total number of files used for validation: 4953\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = False\n",
    "geowiki_subset = 'world' # if add_geowiki=False this will be ignored\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.755\n",
      "RF precision test set: 0.522\n",
      "RF recall test set: 0.836\n",
      "RF f1-score test set: 0.643\n",
      "RF accuracy test set: 0.626\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Total number of files used for training: 19808\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Total number of files used for training: 19808\n",
      "Number of instances in Geowiki validation set: 4953\n",
      "Total number of files used for validation: 4953\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.691\n",
      "RF precision test set: 0.53\n",
      "RF recall test set: 0.732\n",
      "RF f1-score test set: 0.615\n",
      "RF accuracy test set: 0.631\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Geowiki neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 632\n",
      "Total number of files used for training: 632\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 632\n",
      "Total number of files used for training: 632\n",
      "Number of instances in Geowiki validation set: 158\n",
      "Total number of files used for validation: 158\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = False\n",
    "geowiki_subset = 'neighbours1' # if add_geowiki=False this will be ignored\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.842\n",
      "RF precision test set: 0.695\n",
      "RF recall test set: 0.798\n",
      "RF f1-score test set: 0.743\n",
      "RF accuracy test set: 0.778\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 632\n",
      "Total number of files used for training: 632\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 632\n",
      "Total number of files used for training: 632\n",
      "Number of instances in Geowiki validation set: 158\n",
      "Total number of files used for validation: 158\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.778\n",
      "RF precision test set: 0.723\n",
      "RF recall test set: 0.47\n",
      "RF f1-score test set: 0.57\n",
      "RF accuracy test set: 0.714\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Geowiki nigeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Total number of files used for validation: 91\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = False\n",
    "geowiki_subset = 'nigeria' # if add_geowiki=False this will be ignored\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.755\n",
      "RF precision test set: 0.495\n",
      "RF recall test set: 0.891\n",
      "RF f1-score test set: 0.637\n",
      "RF accuracy test set: 0.591\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Total number of files used for validation: 91\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.606\n",
      "RF precision test set: 0.471\n",
      "RF recall test set: 0.574\n",
      "RF f1-score test set: 0.517\n",
      "RF accuracy test set: 0.569\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training only with Nigeria train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 454\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = False\n",
    "add_nigeria = True\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.911\n",
      "RF precision test set: 0.774\n",
      "RF recall test set: 0.787\n",
      "RF f1-score test set: 0.78\n",
      "RF accuracy test set: 0.822\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 454\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.88\n",
      "RF precision test set: 0.749\n",
      "RF recall test set: 0.765\n",
      "RF f1-score test set: 0.757\n",
      "RF accuracy test set: 0.802\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True) # geowiki subset doesn't matter here\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training using Nigeria validation set as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 913\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 454\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = False\n",
    "add_nigeria = True\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.919\n",
      "RF precision test set: 0.79\n",
      "RF recall test set: 0.76\n",
      "RF f1-score test set: 0.774\n",
      "RF accuracy test set: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Normalizing dicts will be the same anyways as they were calculated with all \n",
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using validation data for training seems to worsen the results a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train on geowiki and nigeria combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Geowiki world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 20721\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 20721\n",
      "Number of instances in Geowiki validation set: 4953\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 5407\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = True\n",
    "geowiki_subset = 'world'\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.796\n",
      "RF precision test set: 0.569\n",
      "RF recall test set: 0.858\n",
      "RF f1-score test set: 0.684\n",
      "RF accuracy test set: 0.681\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 20721\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 19808\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 20721\n",
      "Number of instances in Geowiki validation set: 4953\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 5407\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.722\n",
      "RF precision test set: 0.587\n",
      "RF recall test set: 0.667\n",
      "RF f1-score test set: 0.624\n",
      "RF accuracy test set: 0.677\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Geowiki neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 632\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1545\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 632\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1545\n",
      "Number of instances in Geowiki validation set: 158\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 612\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = True\n",
    "geowiki_subset = 'neighbours1'\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset=geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.916\n",
      "RF precision test set: 0.791\n",
      "RF recall test set: 0.765\n",
      "RF f1-score test set: 0.778\n",
      "RF accuracy test set: 0.824\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Ghana_Togo_Nigeria_Cameroon_Benin.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 632\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1545\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 632\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1545\n",
      "Number of instances in Geowiki validation set: 158\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 612\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.887\n",
      "RF precision test set: 0.764\n",
      "RF recall test set: 0.743\n",
      "RF f1-score test set: 0.753\n",
      "RF accuracy test set: 0.804\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Geowiki Nigeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 545\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = True\n",
    "geowiki_subset = 'nigeria'\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset=geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.915\n",
      "RF precision test set: 0.782\n",
      "RF recall test set: 0.825\n",
      "RF f1-score test set: 0.803\n",
      "RF accuracy test set: 0.837\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only with S2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 545\n",
      "Number of instances in Nigeria testing set: 455\n",
      "\n",
      "RF roc-auc test set: 0.887\n",
      "RF precision test set: 0.755\n",
      "RF recall test set: 0.809\n",
      "RF f1-score test set: 0.781\n",
      "RF accuracy test set: 0.818\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset, S2_features_only=True)\n",
    "print('')\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train on geowiki (nigeria subset -> best) and nigeria combined (S2 channels only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 545\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = True\n",
    "geowiki_subset = 'nigeria'\n",
    "S2_features_only = True\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset=geowiki_subset, S2_features_only=S2_features_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.755\n",
      "RF precision test set: 0.495\n",
      "RF recall test set: 0.891\n",
      "RF f1-score test set: 0.637\n",
      "RF accuracy test set: 0.591\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train on Geowiki Nigeria only --> this shows the value of the hand-labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Total number of files used for training: 361\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Total number of files used for validation: 91\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = False\n",
    "geowiki_subset = 'nigeria'\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset=geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.755\n",
      "RF precision test set: 0.495\n",
      "RF recall test set: 0.891\n",
      "RF f1-score test set: 0.637\n",
      "RF accuracy test set: 0.591\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train on Geowiki Nigeria only (with validation set for training too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.763\n",
      "RF precision test set: 0.5\n",
      "RF recall test set: 0.891\n",
      "RF f1-score test set: 0.64\n",
      "RF accuracy test set: 0.598\n"
     ]
    }
   ],
   "source": [
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train on geowiki and nigeria combined + validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Loading normalizing dict geowiki_normalizing_dict_Nigeria.h5\n",
      "Creating Geowiki train split\n",
      "Creating Geowiki val split\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of model parameters: 25473\n",
      "Number of instances in Geowiki training set: 361\n",
      "Number of instances in Nigeria training set: 913\n",
      "Total number of files used for training: 1274\n",
      "Number of instances in Geowiki validation set: 91\n",
      "Number of instances in Nigeria validation set: 454\n",
      "Total number of files used for validation: 545\n",
      "Number of instances in Nigeria testing set: 455\n"
     ]
    }
   ],
   "source": [
    "add_geowiki = True\n",
    "add_nigeria = True\n",
    "geowiki_subset = 'nigeria'\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = get_dataset_splits(add_geowiki, add_nigeria, geowiki_subset=geowiki_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF roc-auc test set: 0.923\n",
      "RF precision test set: 0.799\n",
      "RF recall test set: 0.825\n",
      "RF f1-score test set: 0.812\n",
      "RF accuracy test set: 0.846\n"
     ]
    }
   ],
   "source": [
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_probs = rf.predict_proba(X_test)[:, 1] # for roc_auc_score\n",
    "metrics = get_metrics(y_test, y_probs) # results are a bit better than in notebook 15 and 17 possibly due to correction in normalization of test set with training set nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropharvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
